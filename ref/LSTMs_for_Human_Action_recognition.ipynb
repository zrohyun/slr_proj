{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_wY3BV9YMt7"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/0hyunU/slr_proj/blob/main/ref/LSTMs_for_Human_Action_recognition.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Code from [machinelearningmastery](https://machinelearningmastery.com/how-to-develop-rnn-models-for-human-activity-recognition-time-series-classification/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCpTPVP3YCrd"
      },
      "outputs": [],
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip > /dev/null\n",
        "!unzip UCI\\ HAR\\ Dataset.zip > /dev/null\n",
        "!mv ./UCI\\ HAR\\ Dataset ./HARDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm7OYI15YZ6n"
      },
      "source": [
        "* Activity Recognition Using Smartphones Dataset\n",
        "* Develop an LSTM Network Model\n",
        "* Develop a CNN-LSTM Network Model\n",
        "* Develop a ConvLSTM Network Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEHF6G1PYllh"
      },
      "source": [
        "# Activity Recognition Using Smartphones Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOSoT8S9Y_ZI"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "\n",
        "`총 9개의 feature( total_acc, body_acc, body_gy ) * 3, 128의 window_size를 가진  (128 * 9) 혹은 (1152,1)의 shape을 가진 input data`\n",
        "-- \n",
        "-- --\n",
        "\n",
        "There are three main signal types in the raw data: total acceleration, body acceleration, and body gyroscope. Each has 3 axises of data. This means that there are a total of nine variables for each time step.\n",
        "\n",
        "Further, each series of data has been partitioned into overlapping windows of 2.56 seconds of data, or 128 time steps. These windows of data correspond to the windows of engineered features (rows) in the previous section.\n",
        "\n",
        "This means that one row of data has (128 * 9), or 1,152 elements. This is a little less than double the size of the 561 element vectors in the previous section and it is likely that there is some redundant data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1hrfEJLSiSix"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from numpy import mean, std, dstack\n",
        "\n",
        "from pandas import read_csv\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "from tensorflow.keras.layers import LSTM, TimeDistributed, ConvLSTM2D\n",
        "from tensorflow.keras.layers import MaxPooling1D, Conv1D\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgrhZrrFYWNV"
      },
      "outputs": [],
      "source": [
        "# load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
        "\treturn dataframe.values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPI34xLQZQpc"
      },
      "outputs": [],
      "source": [
        "# load a list of files into a 3D array of [samples, timesteps, features]\n",
        "def load_group(filenames, prefix=''):\n",
        "\tloaded = list()\n",
        "\tfor name in filenames:\n",
        "\t\tdata = load_file(prefix + name)\n",
        "\t\tloaded.append(data)\n",
        "\t# stack group so that features are the 3rd dimension\n",
        "\tloaded = dstack(loaded)\n",
        "\treturn loaded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtXbDoE3ZPfP"
      },
      "outputs": [],
      "source": [
        "# load a dataset group, such as train or test\n",
        "def load_dataset_group(group, prefix=''):\n",
        "\tfilepath = prefix + group + '/Inertial Signals/'\n",
        "\t# load all 9 files as a single array\n",
        "\tfilenames = list()\n",
        "\t# total acceleration\n",
        "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
        "\t# body acceleration\n",
        "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
        "\t# body gyroscope\n",
        "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
        "\t# load input data\n",
        "\tX = load_group(filenames, filepath)\n",
        "\t# load class output\n",
        "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
        "\treturn X, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYW74vJFZOT0"
      },
      "outputs": [],
      "source": [
        "# load the dataset, returns train and test X and y elements\n",
        "def load_dataset(prefix=''):\n",
        "\t# load all train\n",
        "\ttrainX, trainy = load_dataset_group('train', prefix + 'HARDataset/')\n",
        "\tprint(trainX.shape, trainy.shape)\n",
        "\t# load all test\n",
        "\ttestX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n",
        "\tprint(testX.shape, testy.shape)\n",
        "\t# zero-offset class values\n",
        "\ttrainy = trainy - 1\n",
        "\ttesty = testy - 1\n",
        "\t# one hot encode y\n",
        "\ttrainy = to_categorical(trainy)\n",
        "\ttesty = to_categorical(testy)\n",
        "\tprint(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
        "\treturn trainX, trainy, testX, testy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJdh0Y-Qaktc",
        "outputId": "2a26da47-2b00-4ae5-add8-ee0b8efeb70c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7352, 128, 9) (7352, 1)\n",
            "(2947, 128, 9) (2947, 1)\n",
            "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n"
          ]
        }
      ],
      "source": [
        "trainX, trainy, testX, testy = load_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6PzntikbApi",
        "outputId": "a29276a2-747e-4a34-9cf6-d6e2360377d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((7352, 128, 9), (7352, 6), (2947, 128, 9), (2947, 6))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainX.shape, trainy.shape, testX.shape, testy.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZcxkVHXikuC"
      },
      "source": [
        "# Develop an LSTM Network Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zl8bYWVub1Ia"
      },
      "outputs": [],
      "source": [
        "# fit and evaluate a model\n",
        "def evaluate_model(trainX, trainy, testX, testy):\n",
        "\tverbose, epochs, batch_size = 0, 15, 64\n",
        "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(100, activation='relu'))\n",
        "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# fit network\n",
        "\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "\t# evaluate model\n",
        "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
        "\treturn accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDZKf08IgQ3o"
      },
      "outputs": [],
      "source": [
        "# summarize scores\n",
        "def summarize_results(scores):\n",
        "\tprint(scores)\n",
        "\tm, s = mean(scores), std(scores)\n",
        "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
        " \n",
        "# run an experiment\n",
        "def run_experiment(repeats=10):\n",
        "\t# load data\n",
        "\ttrainX, trainy, testX, testy = load_dataset()\n",
        "\t# repeat experiment\n",
        "\tscores = list()\n",
        "\tfor r in tqdm(range(repeats)):\n",
        "\t\tscore = evaluate_model(trainX, trainy, testX, testy)\n",
        "\t\tscore = score * 100.0\n",
        "\t\tprint('>#%d: %.3f' % (r+1, score))\n",
        "\t\tscores.append(score)\n",
        "\t# summarize results\n",
        "\tsummarize_results(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SRTH6nmgTcO"
      },
      "outputs": [],
      "source": [
        "# run the experiment\n",
        "run_experiment()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRKZtWEAipeZ"
      },
      "source": [
        "# Develop a CNN-LSTM Network Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdKnQJ6TjlyT",
        "outputId": "c91bc8c4-d6e7-4e0a-b5e3-467083403004"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((7352, 4, 32, 9), (2947, 4, 32, 9))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "# reshape data into time steps of sub-sequences\n",
        "n_steps, n_length = 4, 32\n",
        "trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
        "testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
        "\n",
        "trainX.shape, testX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjsZT_hhi9JR"
      },
      "outputs": [],
      "source": [
        "# fit and evaluate a model\n",
        "def cnn_lstm_eval(trainX, trainy, testX, testy):\n",
        "\t# define model\n",
        "\tverbose, epochs, batch_size = 0, 25, 64\n",
        "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "\t# reshape data into time steps of sub-sequences\n",
        "\tn_steps, n_length = 4, 32\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
        "\ttestX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=(None,n_length,n_features)))\n",
        "\tmodel.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
        "\tmodel.add(TimeDistributed(Dropout(0.5)))\n",
        "\tmodel.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "\tmodel.add(TimeDistributed(Flatten()))\n",
        "\tmodel.add(LSTM(100))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(100, activation='relu'))\n",
        "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# fit network\n",
        "\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "\t# evaluate model\n",
        "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
        "\treturn accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn3v-S8mirHc"
      },
      "outputs": [],
      "source": [
        "\n",
        " \n",
        "# summarize scores\n",
        "def summarize_results(scores):\n",
        "\tprint(scores)\n",
        "\tm, s = mean(scores), std(scores)\n",
        "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
        " \n",
        "# run an experiment\n",
        "def run_experiment(repeats=10):\n",
        "\t# load data\n",
        "\ttrainX, trainy, testX, testy = load_dataset()\n",
        "\t# repeat experiment\n",
        "\tscores = list()\n",
        "\tfor r in tqdm(range(repeats)):\n",
        "\t\tscore = cnn_lstm_eval(trainX, trainy, testX, testy)\n",
        "\t\tscore = score * 100.0\n",
        "\t\tprint('>#%d: %.3f' % (r+1, score))\n",
        "\t\tscores.append(score)\n",
        "\t# summarize results\n",
        "\tsummarize_results(scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtFfA6lyjayD"
      },
      "outputs": [],
      "source": [
        "# run the experiment\n",
        "run_experiment()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeO3os05ELl9"
      },
      "source": [
        "# Develop a ConvLSTM Network Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8fze_NxFM-o",
        "outputId": "d75a2d7b-23cf-4fe8-bd0f-90a81aa0ed22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([1, 4, 1, 30, 64])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample = np.ones((1,4,1,32,9))\n",
        "n_steps,_, n_length, n_features = sample.shape[1:]\n",
        "ConvLSTM2D(filters=64, kernel_size=(1,3), activation='relu',return_sequences=True, input_shape=(n_steps, 1, n_length, n_features))(sample).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3yrv4mgGVz_",
        "outputId": "8f06df1a-096c-4155-e91e-5e11760e40e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 4, 1, 32, 9)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample = np.ones((1,128,9))\n",
        "# reshape into subsequences (samples, time steps, rows, cols, channels)\n",
        "n_steps, n_length = 4, 32\n",
        "sample = sample.reshape((sample.shape[0], n_steps, 1, n_length, n_features))\n",
        "sample.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YqmLNTJETbE"
      },
      "outputs": [],
      "source": [
        "# fit and evaluate a model\n",
        "def evaluate_model(trainX, trainy, testX, testy):\n",
        "\t# define model\n",
        "\tverbose, epochs, batch_size = 0, 25, 64\n",
        "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "\t# reshape into subsequences (samples, time steps, rows, cols, channels)\n",
        "\tn_steps, n_length = 4, 32\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], n_steps, 1, n_length, n_features))\n",
        "\ttestX = testX.reshape((testX.shape[0], n_steps, 1, n_length, n_features))\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(ConvLSTM2D(filters=64, kernel_size=(1,3), activation='relu', input_shape=(n_steps, 1, n_length, n_features)))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(100, activation='relu'))\n",
        "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# fit network\n",
        "\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "\t# evaluate model\n",
        "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
        "\treturn accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5at9CL5FG6D"
      },
      "outputs": [],
      "source": [
        "# summarize scores\n",
        "def summarize_results(scores):\n",
        "\tprint(scores)\n",
        "\tm, s = mean(scores), std(scores)\n",
        "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ck0u87AVFJC-"
      },
      "outputs": [],
      "source": [
        "# run an experiment\n",
        "def run_experiment(repeats=10):\n",
        "\t# load data\n",
        "\ttrainX, trainy, testX, testy = load_dataset()\n",
        "\t# repeat experiment\n",
        "\tscores = list()\n",
        "\tfor r in range(repeats):\n",
        "\t\tscore = evaluate_model(trainX, trainy, testX, testy)\n",
        "\t\tscore = score * 100.0\n",
        "\t\tprint('>#%d: %.3f' % (r+1, score))\n",
        "\t\tscores.append(score)\n",
        "\t# summarize results\n",
        "\tsummarize_results(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXT8lueAFLDY"
      },
      "outputs": [],
      "source": [
        "# run the experiment\n",
        "run_experiment()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jZcxkVHXikuC",
        "DRKZtWEAipeZ"
      ],
      "name": "LSTMs_for_Human_Action_recognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
