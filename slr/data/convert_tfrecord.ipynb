{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96a9f380-1e59-449e-a9b2-cd871accd39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from slr.data.ksl.keypoint_json_parser import KeypointSeq\n",
    "from slr.data import datagenerator as dg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46695855-23cc-4859-98bd-b19a87b3f56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\slr_proj\\\\slr\\\\data'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0091adb6-4be8-4235-aa65-bf2f09e93130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ksl.datapath import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "78142cd3-cc74-4772-9ff6-310884328de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((138, 137, 3), 8000)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = DataPath(100).data\n",
    "KeypointSeq(x[0]).key_arr.shape, len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7585f535-4d91-49e0-93a5-503af9f09a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [03:31<00:00,  1.18it/s]\n"
     ]
    }
   ],
   "source": [
    "bat = 32\n",
    "for i in tqdm(range(0,len(x),32)):\n",
    "    _ = [KeypointSeq(x[i_]).key_arr for i_ in range(i,i+bat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "31cc3032-ae49-47b0-83c7-9c62bc9285c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tfrec(image,shape, label):\n",
    "    return tf.train.Example(features=tf.train.Features(feature={\n",
    "        'raw_data' : tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),\n",
    "        'data_shape' : tf.train.Feature(bytes_list=tf.train.BytesList(value=[shape])),\n",
    "        'label' : tf.train.Feature(bytes_list=tf.train.BytesList(value=[label]))\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c8841e95-b6e9-4ee4-a6d6-f4d66ce23b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tfrecord(raw_data, labels, writer):\n",
    "\n",
    "    for raw_d, label in zip(raw_data, labels):\n",
    "        raw_d = raw_d.astype(np.float32)\n",
    "        # labels = labels.astype(np.float32)\n",
    "        ex = make_tfrec(raw_d.tobytes(), str(raw_d.shape).encode() ,label.encode())\n",
    "        writer.write(ex.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e0f37e5a-5cd0-4ab4-990c-240febb47b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_tfrecord(data_sample,label,'test.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1930a8f9-b0dd-4fc4-be89-2d77f2f693e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def tf_record_writer(filename, comp = False):\n",
    "    # Code to acquire resource, e.g.:\n",
    "    if comp:\n",
    "        writer = \\\n",
    "            tf.io.TFRecordWriter(\n",
    "            'gzip_'+filename,\n",
    "            tf.io.TFRecordOptions(compression_type=\"GZIP\"))\n",
    "    else:\n",
    "        writer = tf.io.TFRecordWriter(filename)\n",
    "    try:\n",
    "        yield writer\n",
    "    finally:\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "644045ca-5cea-45aa-8ac1-660888caf27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_20056\\159228149.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  raw_data = np.array([\n"
     ]
    }
   ],
   "source": [
    "with tf_record_writer('test.tfrec') as writer:\n",
    "    for i in range(0,len(x),32):\n",
    "        raw_data = np.array([\n",
    "            KeypointSeq(x[i_]).key_arr \n",
    "            for i_ in range(i,i+bat)\n",
    "        ])\n",
    "        labels = np.array([y[i_] for i_ in range(i,i+bat)])\n",
    "        write_tfrecord(raw_data, labels,writer,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ebe3b6ed-d71b-4fb1-8cb3-7a60df1a9bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_20056\\1718429221.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  raw_data = np.array([\n"
     ]
    }
   ],
   "source": [
    "with tf_record_writer('test.tfrec',comp=True) as writer:\n",
    "    for i in range(0,len(x),32):\n",
    "        raw_data = np.array([\n",
    "            KeypointSeq(x[i_]).key_arr \n",
    "            for i_ in range(i,i+bat)\n",
    "        ])\n",
    "        labels = np.array([y[i_] for i_ in range(i,i+bat)])\n",
    "        write_tfrecord(raw_data, labels,writer,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0303e-d842-473f-ab65-59296991c0ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## class 10 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "011961b7-3610-45f1-8c24-21d842d093b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.data.TFRecordDataset('test.tfrec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca77dad4-edb6-4083-b113-5aa2d7fb6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for raw_record in a.take(1):\n",
    "  example = tf.train.Example()\n",
    "  example.ParseFromString(raw_record.numpy())\n",
    "  print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d06f0b7-b443-419b-878d-c1c27df6a38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {data_shape: (), label: (), raw_data: ()}, types: {data_shape: tf.string, label: tf.string, raw_data: tf.string}>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_feature_description = {\n",
    "    'raw_data': tf.io.FixedLenFeature([], tf.string),\n",
    "    'data_shape': tf.io.FixedLenFeature([],tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.train.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "parsed_image_dataset = a.map(_parse_image_function)\n",
    "parsed_image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6dac8b09-1dc0-4a20-a9e1-262f6e3d77ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [00:00, 3043.97it/s]\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "for i in tqdm(parsed_image_dataset):\n",
    "    \n",
    "    raw_data = i['raw_data']\n",
    "    data_shape =  eval(i['data_shape'].numpy().decode())\n",
    "    # print(tf.reshape(tf.io.decode_raw(raw_data, tf.float32),data_shape).shape)\n",
    "# print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b956c9c-d35e-421f-a844-7d25cad09438",
   "metadata": {
    "tags": []
   },
   "source": [
    "## class 100 test no comp\n",
    "- 원래는 3분 30초가 걸리던 load가 2초로 줄었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c1953990-7179-4b32-aa30-a6db1634edb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.data.TFRecordDataset('test.tfrec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f59d317-b1a5-447a-8617-5c5bd5047c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for raw_record in a.take(1):\n",
    "  example = tf.train.Example()\n",
    "  example.ParseFromString(raw_record.numpy())\n",
    "  print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7489d785-fa2a-48e1-8860-9a62c8a61b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {data_shape: (), label: (), raw_data: ()}, types: {data_shape: tf.string, label: tf.string, raw_data: tf.string}>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_feature_description = {\n",
    "    'raw_data': tf.io.FixedLenFeature([], tf.string),\n",
    "    'data_shape': tf.io.FixedLenFeature([],tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.train.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "parsed_image_dataset = a.map(_parse_image_function)\n",
    "parsed_image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1f3bf940-5ed1-4d46-bb51-d878e9c04576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8000it [00:02, 3160.07it/s]\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "for i in tqdm(parsed_image_dataset):\n",
    "    \n",
    "    raw_data = i['raw_data']\n",
    "    data_shape =  eval(i['data_shape'].numpy().decode())\n",
    "    # print(tf.reshape(tf.io.decode_raw(raw_data, tf.float32),data_shape).shape)\n",
    "# print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e728480d-2d0f-41dd-a4d7-5b7297e679c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## class 100 test with comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "987ff92b-cf47-4ea0-84a9-4b84577857fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.data.TFRecordDataset('gzip_test.tfrec','GZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916e8df7-c409-4ca2-8fc8-8a0c4cd3b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for raw_record in a.take(1):\n",
    "  example = tf.train.Example()\n",
    "  example.ParseFromString(raw_record.numpy())\n",
    "  print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4257d05c-243b-42c8-92da-a6f5a56bd238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {data_shape: (), label: (), raw_data: ()}, types: {data_shape: tf.string, label: tf.string, raw_data: tf.string}>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_feature_description = {\n",
    "    'raw_data': tf.io.FixedLenFeature([], tf.string),\n",
    "    'data_shape': tf.io.FixedLenFeature([],tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.train.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "parsed_image_dataset = a.map(_parse_image_function)\n",
    "parsed_image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "be807ed8-f278-4169-9954-d3d2feef5070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8000it [00:02, 3165.11it/s]\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "for i in tqdm(parsed_image_dataset):\n",
    "    \n",
    "    raw_data = i['raw_data']\n",
    "    data_shape =  eval(i['data_shape'].numpy().decode())\n",
    "    # print(tf.reshape(tf.io.decode_raw(raw_data, tf.float32),data_shape).shape)\n",
    "# print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8184b9ad-8b1f-4945-a174-13f138e104ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip -k test.tfrec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd14bf-9136-4fca-8d01-4de383fbff82",
   "metadata": {
    "tags": []
   },
   "source": [
    "## class 100 save to tfrec\n",
    "after seperating test,train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "76dc25f5-d764-470c-b974-0ef92843afe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = DataPath(100).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "02810ec7-09d7-4326-976b-850b8cdca660",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=66, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5638065d-17ea-40a8-bd9a-239fc8fbd93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [tf.ones((1,2,3)) for _ in range(10)]\n",
    "b = np.array([chr(i) for i in range(10)])\n",
    "for a_,b_ in zip(a,b):\n",
    "    print(a_.shape, b_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "285cc078-d922-41d9-bec6-671ecb3a4dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tfrec(image,shape, label):\n",
    "    return tf.train.Example(features=tf.train.Features(feature={\n",
    "        'raw_data' : tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),\n",
    "        'data_shape' : tf.train.Feature(bytes_list=tf.train.BytesList(value=[shape])),\n",
    "        'label' : tf.train.Feature(bytes_list=tf.train.BytesList(value=[label]))\n",
    "    }))\n",
    "\n",
    "def write_tfrecord(raw_data, labels, writer):\n",
    "\n",
    "    for raw_d, label in zip(raw_data, labels):\n",
    "        raw_d = raw_d.astype(np.float32)\n",
    "        # labels = labels.astype(np.float32)\n",
    "        ex = make_tfrec(raw_d.tobytes(), str(raw_d.shape).encode() ,label.encode())\n",
    "        writer.write(ex.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "944e2404-e5d4-4a49-b95e-13a5e64eaef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf_record_writer('train.tfrec',comp=True) as writer:\n",
    "    for i in range(0,len(x_train),32):\n",
    "        raw_data = [\n",
    "            KeypointSeq(x_train[i_]).key_arr\n",
    "            for i_ in range(i,i+bat)]\n",
    "        labels = np.array([y_train[i_] for i_ in range(i,i+bat)])\n",
    "        write_tfrecord(raw_data, labels,writer,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7301757-67a5-435f-9449-0385b0d1f07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf_record_writer('test.tfrec',comp=True) as writer:\n",
    "    for i in range(0,len(x_test),32):\n",
    "        raw_data = [\n",
    "            KeypointSeq(x_test[i_]).key_arr \n",
    "            for i_ in range(i,i+bat)]\n",
    "        labels = np.array([y_test[i_] for i_ in range(i,i+bat)])\n",
    "        write_tfrecord(raw_data, labels,writer,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bedbade-28ea-43be-a9ed-0550ea3ba3b9",
   "metadata": {},
   "source": [
    "## tfrec with keypointgenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "327f8b99-e067-47ab-a0a2-53f205f87bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = DataPath(100).data\n",
    "bat_size=32\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=66, test_size=0.3)\n",
    "train_generator = dg.KeyDataGenerator(x_train,y_train,batch_size = bat_size,scale=True,seq_len=150)\n",
    "test_generator = dg.KeyDataGenerator(x_test,y_test,batch_size = bat_size,scale=True,seq_len=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97de596e-7e5e-4099-85cf-ec8f52e79edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(32, 150, 411)\n",
      "[95 41 70 29 28 72 74 40 16 32 65 85  7  6 72 11 52 15 59 30 77 81 14 17\n",
      " 26 97 15 83 87 22 12 82]\n"
     ]
    }
   ],
   "source": [
    "for i,n in enumerate(train_generator):\n",
    "    print(i)\n",
    "    print(n[0].shape)\n",
    "    print(n[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4991a212-bd91-4bac-9a1a-2432e03952a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 175/175 [01:11<00:00,  2.46it/s]\n"
     ]
    }
   ],
   "source": [
    "with tf_record_writer('train_with_preprocess.tfrec',comp=True) as writer:\n",
    "    for n in tqdm(train_generator):\n",
    "        write_tfrecord(n[0],map(str,n[1]),writer)\n",
    "    # for i in range(0,len(x_train),32):\n",
    "    #     raw_data = [\n",
    "    #         KeypointSeq(x_train[i_]).key_arr\n",
    "    #         for i_ in range(i,i+bat)]\n",
    "    #     labels = np.array([y_train[i_] for i_ in range(i,i+bat)])\n",
    "    #     write_tfrecord(raw_data, labels,writer,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b560f02d-af2f-4b76-8226-72bee6e86f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 75/75 [01:47<00:00,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "with tf_record_writer('train_with_preprocess.tfrec',comp=True) as writer:\n",
    "    for n in tqdm(test_generator):\n",
    "        write_tfrecord(n[0],map(str,n[1]),writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab8ea760-62d6-4eae-8a6e-c84287723d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {data_shape: (), label: (), raw_data: ()}, types: {data_shape: tf.string, label: tf.string, raw_data: tf.string}>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tf.data.TFRecordDataset('gzip_train_with_preprocess.tfrec','GZIP')\n",
    "image_feature_description = {\n",
    "    'raw_data': tf.io.FixedLenFeature([], tf.string),\n",
    "    'data_shape': tf.io.FixedLenFeature([],tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.train.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "parsed_image_dataset = test.map(_parse_image_function)\n",
    "parsed_image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "698e3b02-a158-4104-b4d7-1ec9008a6be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5600it [00:05, 1037.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a=0\n",
    "for i in tqdm(iter(parsed_image_dataset)):\n",
    "    a+=1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f8b3ce-f81b-4cfb-99aa-ba825e70d34f",
   "metadata": {},
   "source": [
    "## load from compressed tfrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6df0f3cb-5e29-420d-993b-5e2f9cb037e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.TFRecordDataset('gzip_train.tfrec','GZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5b8dbe84-ad69-4a89-8ad4-647ed322cc3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {data_shape: (), label: (), raw_data: ()}, types: {data_shape: tf.string, label: tf.string, raw_data: tf.string}>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_feature_description = {\n",
    "    'raw_data': tf.io.FixedLenFeature([], tf.string),\n",
    "    'data_shape': tf.io.FixedLenFeature([],tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.train.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "parsed_image_dataset = train.map(_parse_image_function)\n",
    "parsed_image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a14abc8a-3ac4-41f5-be8f-1ebc3bc84949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5600it [00:05, 938.49it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(parsed_image_dataset):\n",
    "    \n",
    "    raw_data = i['raw_data']\n",
    "    data_shape =  eval(i['data_shape'].numpy().decode())\n",
    "    tf.reshape(tf.io.decode_raw(raw_data, tf.float32),data_shape).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b6088850-d714-4d05-a1db-95c0a28dcbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: {data_shape: (None,), label: (None,), raw_data: (None,)}, types: {data_shape: tf.string, label: tf.string, raw_data: tf.string}>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_image_dataset.batch(32).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0abe6ce1-1ae5-4b38-9647-39367a32f617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5600it [00:05, 948.05it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(parsed_image_dataset):\n",
    "    \n",
    "    raw_data = i['raw_data']\n",
    "    data_shape =  eval(i['data_shape'].numpy().decode())\n",
    "    tf.reshape(tf.io.decode_raw(raw_data, tf.float32),data_shape).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17db55-9d16-4748-b744-b9db5bcf7089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
